{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cicada Species Classification based on their audio (61% acc\n",
        "), dataset:https://www.kaggle.com/datasets/michaelgoh/cicada-species-detection-based-on-acoustic-signals\n",
        "\n"
      ],
      "metadata": {
        "id": "AYaVkmnweBFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv_C21Ys-lU7"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets tensorflow_io matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download('https://www.kaggle.com/datasets/michaelgoh/cicada-species-detection-based-on-acoustic-signals')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uirvwdA6NKGY",
        "outputId": "8d5532e5-2ed9-4d42-f03c-224e89f34448"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cicada-species-detection-based-on-acoustic-signals.zip to ./cicada-species-detection-based-on-acoustic-signals\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 129M/129M [00:07<00:00, 17.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Set the path to your dataset folder\n",
        "dataset_path = '/content/cicada-species-detection-based-on-acoustic-signals/Cicada Species Detection Based on Acoustic Signals/audio (original)/'\n",
        "\n",
        "# Define the cicada species names\n",
        "species_names = ['cassini', 'septendecim', 'septendecula']\n",
        "\n",
        "# Define the desired sample rate and audio length for preprocessing\n",
        "desired_sample_rate = 16000\n",
        "desired_audio_length = 5  # in seconds\n",
        "\n",
        "# Initialize empty lists to store the preprocessed data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over each species\n",
        "for species in species_names:\n",
        "    # Set the path to the species folder\n",
        "    species_folder = os.path.join(dataset_path, species)\n",
        "\n",
        "    # Iterate over each audio file in the species folder\n",
        "    for file_name in os.listdir(species_folder):\n",
        "        # Read the audio file\n",
        "        file_path = os.path.join(species_folder, file_name)\n",
        "        sample_rate, audio_data = wavfile.read(file_path)\n",
        "\n",
        "\n",
        "\n",
        "        # Resample the audio data to the desired sample rate\n",
        "        if sample_rate != desired_sample_rate:\n",
        "            audio_data = np.interp(\n",
        "                np.linspace(\n",
        "                    0, len(audio_data), int(len(audio_data) * (desired_sample_rate / sample_rate))\n",
        "                ), np.arange(len(audio_data)), audio_data\n",
        "            )\n",
        "\n",
        "        # Pad or truncate the audio signal to the desired length\n",
        "        desired_samples = int(desired_sample_rate * desired_audio_length)\n",
        "        if len(audio_data) < desired_samples:\n",
        "            audio_data = np.pad(audio_data, (0, desired_samples - len(audio_data)), 'constant')\n",
        "        elif len(audio_data) > desired_samples:\n",
        "            audio_data = audio_data[:desired_samples]\n",
        "\n",
        "        # Append the preprocessed data and label to the lists\n",
        "        data.append(audio_data)\n",
        "        labels.append(species)\n",
        "\n",
        "# Convert the data and labels to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Encode the labels as integers\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the audio data to values between 0 and 1\n",
        "train_data = train_data / np.max(np.abs(train_data))\n",
        "test_data = test_data / np.max(np.abs(test_data))\n",
        "\n",
        "# Convert labels to categorical format\n",
        "num_classes = len(species_names)\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyGlnFF6T2iy",
        "outputId": "b35808f6-c924-4640-b30e-943b484f5acf"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-2ea4863a9107>:32: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  sample_rate, audio_data = wavfile.read(file_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(desired_samples,), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Uc9rMJFtWFhw"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(test_data, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yWG4k-SWIDw",
        "outputId": "9e1f84c7-a922-4608-99e1-a4a2f5467ebd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 191ms/step - loss: 6.8275 - accuracy: 0.3235 - val_loss: 1.0739 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 4.5166 - accuracy: 0.4118 - val_loss: 1.2377 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 3.8782 - accuracy: 0.5294 - val_loss: 1.3840 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 5.4207 - accuracy: 0.6176 - val_loss: 1.5172 - val_accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 7.1029 - accuracy: 0.6176 - val_loss: 1.6420 - val_accuracy: 0.2222\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 5.7055 - accuracy: 0.6765 - val_loss: 1.7549 - val_accuracy: 0.2222\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 4.9722 - accuracy: 0.6471 - val_loss: 1.8819 - val_accuracy: 0.2222\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 17.2965 - accuracy: 0.6176 - val_loss: 1.9895 - val_accuracy: 0.2222\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 4.3832 - accuracy: 0.6765 - val_loss: 2.0982 - val_accuracy: 0.2222\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 5.9204 - accuracy: 0.6765 - val_loss: 2.2093 - val_accuracy: 0.3333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a2a447746a0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_data, test_labels)\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0-kfmnuWKYJ",
        "outputId": "db850fda-b09e-4140-8cd5-ca58d63fb586"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step - loss: 2.2093 - accuracy: 0.3333\n",
            "Test loss: 2.2093069553375244\n",
            "Test accuracy: 0.3333333432674408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_data)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "actual_labels = np.argmax(test_labels, axis=1)\n",
        "predicted_labels = label_encoder.inverse_transform(predicted_labels)\n",
        "actual_labels = label_encoder.inverse_transform(actual_labels)\n",
        "for i in range(len(test_data)):\n",
        "    print(\"Predicted: {}, Actual: {}\".format(predicted_labels[i], actual_labels[i]))\n",
        "correct_predictions = np.sum(predicted_labels == actual_labels)\n",
        "total_predictions = len(predicted_labels)\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(\"Accuracy: {:.2%}\".format(accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt6anjZDVEjh",
        "outputId": "8e2aaddc-4c56-41c2-d2c0-cc9597cc6b77"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 53ms/step\n",
            "Predicted: septendecim, Actual: septendecula\n",
            "Predicted: cassini, Actual: septendecim\n",
            "Predicted: septendecim, Actual: septendecim\n",
            "Predicted: septendecim, Actual: septendecula\n",
            "Predicted: cassini, Actual: septendecula\n",
            "Predicted: cassini, Actual: septendecula\n",
            "Predicted: cassini, Actual: cassini\n",
            "Predicted: septendecim, Actual: cassini\n",
            "Predicted: cassini, Actual: cassini\n",
            "Accuracy: 33.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dataset_path = '/content/cicada-species-detection-based-on-acoustic-signals/Cicada Species Detection Based on Acoustic Signals/audio (original)/'\n",
        "\n",
        "# Define the cicada species names\n",
        "species_names = ['cassini', 'septendecim', 'septendecula']\n",
        "\n",
        "# Define the desired sample rate and audio length for preprocessing\n",
        "desired_sample_rate = 16000\n",
        "desired_audio_length = 2  # in seconds\n",
        "\n",
        "# Define the number of augmented samples per original sample\n",
        "num_augmented_samples = 3\n",
        "\n",
        "# Initialize empty lists to store the preprocessed data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over each species\n",
        "for species in species_names:\n",
        "    # Set the path to the species folder\n",
        "    species_folder = os.path.join(dataset_path, species)\n",
        "\n",
        "    # Iterate over each audio file in the species folder\n",
        "    for file_name in os.listdir(species_folder):\n",
        "        # Read the audio file\n",
        "        file_path = os.path.join(species_folder, file_name)\n",
        "        audio_data, _ = librosa.load(file_path, sr=desired_sample_rate, duration=desired_audio_length)\n",
        "\n",
        "        # Augment the audio data\n",
        "        augmented_data = []\n",
        "        for _ in range(num_augmented_samples):\n",
        "            # Apply time stretching and pitch shifting\n",
        "            time_stretched = librosa.effects.time_stretch(audio_data, rate=np.random.uniform(0.8, 1.2))\n",
        "            pitch_shifted = librosa.effects.pitch_shift(time_stretched, sr=desired_sample_rate, n_steps=np.random.randint(-3, 3))\n",
        "\n",
        "            # Pad or truncate the augmented audio to the desired length\n",
        "            desired_samples = int(desired_sample_rate * desired_audio_length)\n",
        "            if len(pitch_shifted) < desired_samples:\n",
        "                pitch_shifted = np.pad(pitch_shifted, (0, desired_samples - len(pitch_shifted)), 'constant')\n",
        "            elif len(pitch_shifted) > desired_samples:\n",
        "                pitch_shifted = pitch_shifted[:desired_samples]\n",
        "\n",
        "            augmented_data.append(pitch_shifted)\n",
        "\n",
        "        # Append the preprocessed data and label to the lists\n",
        "        data.extend(augmented_data)\n",
        "        labels.extend([species] * len(augmented_data))\n",
        "\n",
        "# Convert the data and labels to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Encode the labels as integers\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the audio data to values between 0 and 1\n",
        "train_data = train_data / np.max(np.abs(train_data))\n",
        "test_data = test_data / np.max(np.abs(test_data))\n",
        "\n",
        "# Convert labels to categorical format\n",
        "num_classes = len(species_names)\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "MNyIE3LdamVC"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(desired_sample_rate * desired_audio_length,), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "5As-JDoQanUj"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, train_labels, epochs=15, batch_size=32, validation_data=(test_data, test_labels))\n"
      ],
      "metadata": {
        "id": "3lueP9NQbdHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_data)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "actual_labels = np.argmax(test_labels, axis=1)\n",
        "predicted_labels = label_encoder.inverse_transform(predicted_labels)\n",
        "actual_labels = label_encoder.inverse_transform(actual_labels)\n",
        "for i in range(len(test_data)):\n",
        "    print(\"Predicted: {}, Actual: {}\".format(predicted_labels[i], actual_labels[i]))\n",
        "correct_predictions = np.sum(predicted_labels == actual_labels)\n",
        "total_predictions = len(predicted_labels)\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(\"Accuracy: {:.2%}\".format(accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LvqwEYibmr0",
        "outputId": "5ece52eb-dd14-48f6-fbb5-540f48bda025"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 83ms/step\n",
            "Predicted: septendecula, Actual: septendecula\n",
            "Predicted: cassini, Actual: cassini\n",
            "Predicted: septendecula, Actual: septendecula\n",
            "Predicted: cassini, Actual: cassini\n",
            "Predicted: cassini, Actual: cassini\n",
            "Predicted: septendecula, Actual: septendecim\n",
            "Predicted: septendecula, Actual: cassini\n",
            "Predicted: septendecula, Actual: cassini\n",
            "Predicted: septendecula, Actual: cassini\n",
            "Predicted: septendecula, Actual: septendecula\n",
            "Predicted: septendecula, Actual: septendecula\n",
            "Predicted: septendecula, Actual: septendecula\n",
            "Predicted: cassini, Actual: septendecim\n",
            "Predicted: septendecula, Actual: septendecula\n",
            "Predicted: septendecula, Actual: septendecula\n",
            "Predicted: cassini, Actual: septendecula\n",
            "Predicted: cassini, Actual: septendecim\n",
            "Predicted: septendecula, Actual: septendecula\n",
            "Accuracy: 61.11%\n"
          ]
        }
      ]
    }
  ]
}